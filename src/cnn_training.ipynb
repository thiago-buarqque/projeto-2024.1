{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/evry/Desktop/master-degree/repositories/vision-anomaly/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evry/anaconda3/envs/vision-anomaly/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import cv2\n",
    "from progressbar import Bar, DynamicMessage, ProgressBar, ETA\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "# Local application imports\n",
    "from model.model import Model\n",
    "from tasad.tasad_model import TasadModel\n",
    "from tasad.data_loader import MVTecTrainDataset\n",
    "from tasad.data_loader_test import MVTecTestDataset\n",
    "from tasad.utils.utilts_custom_class import *\n",
    "from tasad.utils.utilts_func import *\n",
    "from tasad.data_loader_preprocessed import MVTecPreprocessedDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = \"/home/evry/Desktop/master-degree/repositories/two-stage-coarse-to-fine-image-anomaly-segmentation-and-detection-model/data/images\"\n",
    "processed_dataset_root_path = \"/home/evry/Desktop/master-degree/repositories/two-stage-coarse-to-fine-image-anomaly-segmentation-and-detection-model/processed_data\"\n",
    "\n",
    "def read_data(class_name: str, batch_size=1):\n",
    "    train_dataset = MVTecPreprocessedDataset(root_dir=processed_dataset_root_path + f\"/{class_name}/test/\",resize_shape=[256, 256], datatype=\"jpg\")\n",
    "    test_dataset = MVTecTestDataset(root_dir=dataset_root_path + f\"/{class_name}/test/\", resize_shape=[256, 256])\n",
    "    \n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# dataset_root_path = \"/home/evry/Desktop/master-degree/repositories/two-stage-coarse-to-fine-image-anomaly-segmentation-and-detection-model/data/images\"\n",
    "# anomaly_path = \"/home/evry/Desktop/master-degree/repositories/two-stage-coarse-to-fine-image-anomaly-segmentation-and-detection-model/data/anomaly/images\"\n",
    "# # dataset_root_path = \"/home/evry/Desktop/master-degree/dataset/BTech_Dataset_transformed\"\n",
    "\n",
    "# def read_data(class_name: str, batch_size=1):\n",
    "#     train_dataset = MVTecTrainDataset(root_dir=dataset_root_path + f\"/{class_name}/train/\", anomaly_source_path=anomaly_path, resize_shape=[256, 256])\n",
    "#     test_dataset = MVTecTestDataset(root_dir=dataset_root_path + f\"/{class_name}/test/\", resize_shape=[256, 256])\n",
    "    \n",
    "#     train_loader = DataLoader(dataset = train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     test_loader = DataLoader(dataset = test_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "#     return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_comparison(\n",
    "    class_name: str, \n",
    "    file_name:str, \n",
    "    image, \n",
    "    mask, \n",
    "    reconstruction, \n",
    "    ssim_map, \n",
    "    fas_input, \n",
    "    fas_output, \n",
    "    processed_fas_output, \n",
    "    save_fig: bool, \n",
    "    summary_writer: SummaryWriter, \n",
    "    epoch,\n",
    "    path: str = \"../runs/tasad-vitcnn\",\n",
    "    test=False\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        _input_image = image.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        _mask = mask.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        _fas_input = fas_input.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        _fas_output = fas_output.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        _ssim_map = ssim_map.cpu().numpy()[0][0]\n",
    "        # _processed_fas_output = processed_fas_output.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        \n",
    "        # Create a heatmap from the normalized SSIM map\n",
    "        heatmap = cv2.applyColorMap((_ssim_map * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Convert _input_image to uint8\n",
    "        _input_image_uint8 = (_input_image * 255).astype(np.uint8)\n",
    "\n",
    "        # Overlay the heatmap on the original input image\n",
    "        overlay = cv2.addWeighted(_input_image_uint8, 0.4, heatmap, 0.6, 0)\n",
    "\n",
    "        # Plot the results\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 3))\n",
    "\n",
    "        ax1 = fig.add_subplot(161)\n",
    "        ax1.imshow(_input_image, cmap='gray')\n",
    "        ax1.set_title('ViT-CNN entrada')\n",
    "        ax1.axis(\"off\")\n",
    "        \n",
    "        reconstruction_norm = (reconstruction - reconstruction.min()) / (reconstruction.max() - reconstruction.min())\n",
    "        \n",
    "        ax2 = fig.add_subplot(162)\n",
    "        ax2.imshow(reconstruction_norm.cpu().numpy()[0].transpose(1, 2, 0))\n",
    "        ax2.set_title('ViT-CNN saída')\n",
    "        ax2.axis(\"off\")\n",
    "        \n",
    "        ax3 = fig.add_subplot(163)\n",
    "        ax3.imshow(overlay)\n",
    "        ax3.set_title('ViT-CNN mapa SSIM')\n",
    "        ax3.axis(\"off\")\n",
    "        \n",
    "        ax4 = fig.add_subplot(164)\n",
    "        ax4.imshow(_mask, cmap='gray')\n",
    "        ax4.set_title('Padrão ouro')\n",
    "        ax4.axis(\"off\")\n",
    "        \n",
    "        ax5 = fig.add_subplot(165)\n",
    "        ax5.imshow(_fas_input)\n",
    "        ax5.set_title('Entrada FAS')\n",
    "        ax5.axis(\"off\")\n",
    "        \n",
    "        ax6 = fig.add_subplot(166)\n",
    "        ax6.imshow(_fas_output, cmap='gray')\n",
    "        ax6.set_title('Saída FAS')\n",
    "        ax6.axis(\"off\")\n",
    "        \n",
    "        # ax6 = fig.add_subplot(177)\n",
    "        # ax6.imshow(_processed_fas_output, cmap='gray')\n",
    "        # ax6.set_title('Saída FAS binária')\n",
    "        # ax6.axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        # if plot:\n",
    "        #     plt.show()\n",
    "        \n",
    "        path += f\"/plots/\"\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        if save_fig:\n",
    "            fig.savefig(path + file_name)        \n",
    "\n",
    "        pref = \"train\"\n",
    "        if test:\n",
    "            pref = \"test\"\n",
    "        summary_writer.add_figure(f'{pref} plot', fig, epoch)\n",
    "        \n",
    "        fig.clear()\n",
    "        plt.close()\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vitcnn_output_mask(input_batch, vitcnn):\n",
    "    _, reconstruction = vitcnn(input_batch.cpu())\n",
    "    \n",
    "    reconstruction = reconstruction.cpu()\n",
    "    \n",
    "    SSIM = StructuralSimilarityIndexMeasure(return_full_image=True).cpu()\n",
    "    \n",
    "    ssim_value, ssim_map = SSIM(reconstruction, input_batch.cpu())\n",
    "    \n",
    "    norm_ssim_map = (ssim_map - ssim_map.min()) / (ssim_map.max() - ssim_map.min())\n",
    "    \n",
    "    mean_tensor = norm_ssim_map.mean(dim=1, keepdim=True)\n",
    "\n",
    "    norm_ssim_map = mean_tensor.expand(-1, 3, -1, -1)\n",
    "    \n",
    "    binary_ssim_map = torch.where(norm_ssim_map > 0.85, torch.zeros_like(norm_ssim_map), torch.ones_like(norm_ssim_map))\n",
    "    \n",
    "    return input_batch * binary_ssim_map.cuda(), reconstruction, ssim_value, ssim_map, binary_ssim_map.cpu().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_segmentation_model(\n",
    "    vitcnn: Model,\n",
    "    class_name: str,\n",
    "    dataloader,\n",
    "    epoch: int,\n",
    "    gpu_id,\n",
    "    fas_model: TasadModel,\n",
    "    visualizer: SummaryWriter = None,\n",
    "    print_logs: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Test the segmentation model on the MVTec test dataset.\n",
    "    \n",
    "    Args:\n",
    "    segmentation_model (TasadModel): The main segmentation model to be tested.\n",
    "    class_name (str): The name of the class to be tested.\n",
    "    data_path (str): Path to the dataset.\n",
    "    epoch (int): Current epoch number.\n",
    "    gpu_id: GPU ID for CUDA device.\n",
    "    fas_model (TasadModel, optional): Additional model for further segmentation (if any).\n",
    "    visualizer (TensorboardVisualizer, optional): Tensorboard visualizer for performance plotting.\n",
    "    print_logs (bool, optional): Flag to print logs.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: AP, AP per pixel, AUROC, AUROC per pixel\n",
    "    \"\"\"\n",
    "    \n",
    "    cuda_device = torch.device(f'cuda:{gpu_id}')\n",
    "    img_dimension = 256\n",
    "    image_index = 0\n",
    "\n",
    "    fas_model.eval()\n",
    "\n",
    "    dataset = dataloader.dataset\n",
    "    total_pixel_scores = np.zeros((img_dimension * img_dimension * len(dataset)))\n",
    "    total_gt_pixel_scores = np.zeros((img_dimension * img_dimension * len(dataset)))\n",
    "    mask_count = 0\n",
    "\n",
    "    anomaly_score_gt = []\n",
    "    anomaly_score_prediction = []\n",
    "    \n",
    "    widgets = [\n",
    "        DynamicMessage('test'),\n",
    "        Bar(marker='=', left='[', right=']'),\n",
    "        ' ', ETA(),\n",
    "    ]\n",
    "\n",
    "    with ProgressBar(widgets=widgets, max_value=len(dataset)) as progress_bar:\n",
    "        saved_in_this_epoch = False\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            vitcnn_input = sample_batched[\"augmented_image\"].cuda(cuda_device)\n",
    "            original_image = plt.imread(dataloader.dataset.images[i_batch]) \n",
    "            resized_original_image = cv2.resize(original_image, (img_dimension, img_dimension))\n",
    "\n",
    "            has_anomaly = sample_batched[\"has_anomaly\"].cpu().detach().numpy()\n",
    "            anomaly_score_gt.append(has_anomaly)\n",
    "            ground_truth_mask = sample_batched[\"anomaly_mask\"].cpu()\n",
    "            \n",
    "            ground_truth_mask_np = ground_truth_mask.detach().numpy()[0, :, :, :].transpose((1, 2, 0))\n",
    "                \n",
    "            fas_input, vitcnn_reconstruction, vitcnn_ssim_value, vitcnn_ssim_map, vitcnn_binary_ssim_map = \\\n",
    "                    get_vitcnn_output_mask(vitcnn_input, vitcnn)\n",
    "                \n",
    "            fas_output = fas_model(fas_input).cpu()\n",
    "            \n",
    "            vitcnn_binary_ssim_map = vitcnn_binary_ssim_map.to(fas_output.device)\n",
    "            \n",
    "            processed_fas_output = fas_output * vitcnn_binary_ssim_map.mean(dim=1, keepdim=True)\n",
    "            \n",
    "            processed_fas_output = torch.where(fas_output < 0.3, torch.zeros_like(processed_fas_output), torch.ones_like(processed_fas_output))\n",
    "            \n",
    "            if has_anomaly[0] and not saved_in_this_epoch:\n",
    "                saved_in_this_epoch = True\n",
    "                \n",
    "                save_comparison(\n",
    "                    class_name=class_name,\n",
    "                    file_name=f\"test_sample_epoch_{epoch}.jpg\",\n",
    "                    image=vitcnn_input,\n",
    "                    mask=ground_truth_mask,\n",
    "                    reconstruction=vitcnn_reconstruction,\n",
    "                    ssim_map=vitcnn_ssim_map,\n",
    "                    fas_input=fas_input,\n",
    "                    fas_output=fas_output,\n",
    "                    processed_fas_output=processed_fas_output,\n",
    "                    save_fig=True,\n",
    "                    summary_writer=visualizer,\n",
    "                    epoch=epoch,\n",
    "                    path=f\"../runs/tasad-vitcnn/{class_name}/test\",\n",
    "                    test=True)\n",
    "                \n",
    "            # output_mask_np = processed_fas_output.detach().cpu().numpy()\n",
    "            # output = fas_output                                                                                                                                   \n",
    "            \n",
    "            # fas_input = torch.tensor(seg_module(vitcnn_input, cas_output, th_pix=0.95, th_val=30)).cuda(cuda_device)\n",
    "            # fas_output = fas_model(fas_input)\n",
    "            # combined_output = fas_output + cas_output\n",
    "\n",
    "            output_mask_np = processed_fas_output[0, 0, :, :].detach().cpu().numpy()\n",
    "            output = fas_output                                                                                                                                   \n",
    "           \n",
    "            try:\n",
    "                fas_input_np = fas_input.detach().cpu().numpy()[0, :, :, :].transpose((1, 2, 0))   \n",
    "                fas_input_rgb = cv2.cvtColor(fas_input_np, cv2.COLOR_BGR2RGB)\n",
    "                query_image_rgb = cv2.cvtColor(resized_original_image, cv2.COLOR_BGR2RGB)\n",
    "                out_mask_fas_np = abs(fas_output.detach().cpu().numpy()[0, :, :, :].transpose((1, 2, 0))[:,:,0])/torch.max(fas_output).item()\n",
    "                # out_mask_cas_np = abs(cas_output.detach().cpu().numpy()[0, :, :, :].transpose((1, 2, 0))[:,:,0])/torch.max(cas_output).item()\n",
    "                combined_output_normalized = abs(out_mask_fas_np)\n",
    "                combined_output_normalized = combined_output_normalized/np.max(combined_output_normalized)\n",
    "                \n",
    "                all_images = [query_image_rgb,  ground_truth_mask_np, fas_input_rgb, out_mask_fas_np, combined_output_normalized] \n",
    "                # Image saving function can be implemented here if needed\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "            image_index += 1\n",
    "            averaged_output_mask = torch.nn.functional.avg_pool2d(output, 21, stride=1, padding=21 // 2).cpu().detach().numpy()\n",
    "            image_score = np.max(averaged_output_mask)\n",
    "\n",
    "            anomaly_score_prediction.append(image_score)\n",
    "\n",
    "            flat_gt_mask = ground_truth_mask_np.flatten()\n",
    "            flat_output_mask = output_mask_np.flatten()\n",
    "            \n",
    "            total_pixel_scores[mask_count * img_dimension * img_dimension:(mask_count + 1) * img_dimension * img_dimension] = flat_output_mask\n",
    "            total_gt_pixel_scores[mask_count * img_dimension * img_dimension:(mask_count + 1) * img_dimension * img_dimension] = flat_gt_mask\n",
    "            mask_count += 1\n",
    "            \n",
    "            progress_bar.update(\n",
    "                i_batch,\n",
    "                test=f\"({i_batch}/{len(dataset)}) Class {class_name} \")\n",
    "\n",
    "    anomaly_score_prediction = np.array(anomaly_score_prediction)\n",
    "    anomaly_score_gt = np.array(anomaly_score_gt)\n",
    "    auroc = roc_auc_score(anomaly_score_gt, anomaly_score_prediction)\n",
    "    ap = average_precision_score(anomaly_score_gt, anomaly_score_prediction)\n",
    "\n",
    "    total_gt_pixel_scores = total_gt_pixel_scores.astype(np.uint8)\n",
    "    total_gt_pixel_scores = total_gt_pixel_scores[:img_dimension * img_dimension * mask_count]\n",
    "    total_pixel_scores = total_pixel_scores[:img_dimension * img_dimension * mask_count]\n",
    "    \n",
    "    auroc_pixel = roc_auc_score(total_gt_pixel_scores, total_pixel_scores)\n",
    "    ap_pixel = average_precision_score(total_gt_pixel_scores, total_pixel_scores)\n",
    "        \n",
    "    if visualizer:\n",
    "        visualizer.add_scalar(\"test_AP_pixel\", ap_pixel, epoch)\n",
    "        visualizer.add_scalar(\"test_AUROC_pixel\", auroc_pixel, epoch)\n",
    "        visualizer.add_scalar(\"test_AUROC\", auroc, epoch)\n",
    "        visualizer.add_scalar(\"test_AP\", ap, epoch)\n",
    "    \n",
    "    if print_logs:\n",
    "        print(f\"{datetime.now()} Test for epoch {epoch}: Class {class_name} Pixel AP {ap_pixel:.2f} Pixel AUC {auroc_pixel:.2f} Image AUC {auroc:.2f} Image AP {ap:.2f}\")\n",
    "    \n",
    "    del total_gt_pixel_scores\n",
    "    del total_pixel_scores\n",
    "    del anomaly_score_gt\n",
    "    del anomaly_score_prediction\n",
    "    del progress_bar\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return ap, ap_pixel, auroc, auroc_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasad.loss import SSIM\n",
    "from tasad.tasad_model import TasadModel\n",
    "\n",
    "\n",
    "progressbar_widgets = [\n",
    "    DynamicMessage('log', format = '{formatted_value}'),\n",
    "    Bar(marker='=', left='[', right=']'),\n",
    "    ' ',  ETA(),\n",
    "]\n",
    "\n",
    "def train_tasad_and_vitcnn(\n",
    "    class_name: str,\n",
    "    vitcnn,\n",
    "    epochs=200,\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=4\n",
    "):\n",
    "    train_loader, test_loader = read_data(class_name, batch_size)\n",
    "    \n",
    "    print(f\"\\n\\nStarting training for class: {class_name}\\n\")\n",
    "    print(f\"Info: Found {len(train_loader.dataset)} sample for training\")\n",
    "    print(f\"Info: Found {len(test_loader.dataset)} sample for test\")    \n",
    "\n",
    "    fas_model = TasadModel(in_channels=3, out_channels=1, base_width=64).cuda()\n",
    "    fas_model.apply(weights_init)\n",
    "    fas_parameters_amount = TasadModel.get_n_params(fas_model)\n",
    "    fas_model.train()\n",
    "    \n",
    "    print(f\"Info: Initializing fas with {fas_parameters_amount} parameters\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam([{\"params\": fas_model.parameters(), \"lr\": learning_rate}])\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [epochs*0.1, epochs*0.3, epochs*0.7], gamma=0.1, last_epoch=-1)\n",
    "\n",
    "    best_epoch = -1\n",
    "    best_avg_metrics = -1e10\n",
    "    \n",
    "    summary_writer = SummaryWriter(log_dir=f'../runs/tasad-vitcnn/{class_name}')\n",
    "    \n",
    "    loss_l2 = torch.nn.modules.loss.MSELoss()\n",
    "    # SSIM = StructuralSimilarityIndexMeasure().cpu()\n",
    "    loss_ssim = SSIM(0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sum_loss = 0\n",
    "        sum_ssim_loss = 0\n",
    "        sum_l2_loss = 0\n",
    "        saved_anomaly_in_this_epoch = False\n",
    "        with ProgressBar(widgets=progressbar_widgets, max_value=train_loader.__len__() + 1) as progress_bar:\n",
    "            for batch_index, batch in enumerate(train_loader):\n",
    "                input_batch = batch['augmented_image'].cuda()\n",
    "                ground_truth_batch = batch['anomaly_mask'].cpu()\n",
    "                has_anomaly = batch['has_anomaly'].cuda()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                fas_input, vitcnn_reconstruction, vitcnn_ssim_value, vitcnn_ssim_map, vitcnn_binary_ssim_map = \\\n",
    "                    get_vitcnn_output_mask(input_batch, vitcnn)\n",
    "                    \n",
    "                #print(f\"Fas Input Shape: {fas_input.shape}, Range: {fas_input.min()} - {fas_input.max()}\")\n",
    "                \n",
    "                fas_output = fas_model(fas_input).cpu()\n",
    "                \n",
    "                #print(f\"Fas Output Shape: {fas_output.shape}, Range: {fas_output.min()} - {fas_output.max()}\")\n",
    "                \n",
    "                # vitcnn_binary_ssim_map = vitcnn_binary_ssim_map.to(fas_output.device)\n",
    "                \n",
    "                # processed_fas_output = fas_output.clone() * vitcnn_binary_ssim_map.mean(dim=1, keepdim=True)\n",
    "                \n",
    "                # processed_fas_output = torch.where(fas_output < 0.3, torch.zeros_like(processed_fas_output), torch.ones_like(processed_fas_output))\n",
    "                \n",
    "                if has_anomaly[0] and not saved_anomaly_in_this_epoch:\n",
    "                    saved_anomaly_in_this_epoch = True\n",
    "                    \n",
    "                    save_comparison(\n",
    "                        class_name=class_name,\n",
    "                        file_name=f\"train_anom_sample_epoch_{epoch}.jpg\",\n",
    "                        image=input_batch,\n",
    "                        mask=ground_truth_batch,\n",
    "                        reconstruction=vitcnn_reconstruction,\n",
    "                        ssim_map=vitcnn_ssim_map,\n",
    "                        fas_input=fas_input,\n",
    "                        fas_output=fas_output,\n",
    "                        processed_fas_output=None,\n",
    "                        save_fig=True,\n",
    "                        summary_writer=summary_writer,\n",
    "                        epoch=epoch,\n",
    "                        path=f\"../runs/tasad-vitcnn/{class_name}/train\")\n",
    "                \n",
    "                l2_loss = loss_l2(fas_output, ground_truth_batch).cpu()\n",
    "                    \n",
    "                sum_l2_loss += l2_loss.item()\n",
    "                \n",
    "                ssim_loss = loss_ssim(fas_output, ground_truth_batch).cpu()\n",
    "                \n",
    "                sum_ssim_loss += ssim_loss.item()\n",
    "                \n",
    "                loss = l2_loss + ssim_loss\n",
    "                \n",
    "                sum_loss += loss.item()\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                progress_bar.update(\n",
    "                    batch_index, \n",
    "                    log=f\"({epoch+1}) Class: {class_name} | L2 loss: {(sum_l2_loss / (batch_index + 1)):.2f} | SSIM loss: {(sum_ssim_loss / (batch_index + 1)):.2f} | L2 and SSIM loss: {(sum_loss / (batch_index + 1)):.2f} \")\n",
    "        \n",
    "        del input_batch\n",
    "        del ground_truth_batch\n",
    "        del has_anomaly\n",
    "        del batch\n",
    "        del fas_input\n",
    "        del vitcnn_reconstruction\n",
    "        del vitcnn_ssim_value\n",
    "        del vitcnn_ssim_map\n",
    "        del vitcnn_binary_ssim_map\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        ap, ap_pixel, auroc, auroc_pixel = test_segmentation_model(\n",
    "            vitcnn=vitcnn,\n",
    "            class_name=class_name,\n",
    "            dataloader=test_loader,\n",
    "            epoch=epoch,\n",
    "            gpu_id=0,\n",
    "            fas_model=fas_model,\n",
    "            visualizer=summary_writer,\n",
    "            print_logs=False\n",
    "        )\n",
    "        \n",
    "        fas_model.train()\n",
    "\n",
    "        print(f\"(test) AP: {ap:.2f} | AP pixel: {ap_pixel:.2f} | AUROC: {auroc:.2f} AUROC pixel: {auroc_pixel:.2f}\")\n",
    "        scheduler.step()\n",
    "        \n",
    "        summary_writer.add_scalar('fas_l2_loss', sum_l2_loss / len(train_loader), epoch)\n",
    "        summary_writer.add_scalar('fas_ssim_loss', sum_ssim_loss / len(train_loader), epoch)\n",
    "        \n",
    "        avg_metrics = (ap + ap_pixel + auroc + auroc_pixel) / 4\n",
    "        # avg_loss = sum_loss / len(train_loader)\n",
    "        if avg_metrics > best_avg_metrics and abs(best_avg_metrics - avg_metrics) >= 0.01:\n",
    "            best_avg_metrics = avg_metrics\n",
    "            best_epoch = epoch + 1\n",
    "            \n",
    "            torch.save(fas_model.state_dict(), os.path.join(f\"../tasad_models/tasad_{class_name}.pt\"))\n",
    "        elif (epoch + 1) - best_epoch >= 20:\n",
    "            print(f\"\\nStop training for class: {class_name}. Last best metrics avg: {best_avg_metrics} ({best_epoch})\\n\\n\")\n",
    "            torch.save(fas_model.state_dict(), os.path.join(f\"../tasad_models/tasad_{class_name}_last.pt\"))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vit_model(class_name: str):\n",
    "    model = Model(patch_size=16, depth=32).cpu()\n",
    "    model.load_state_dict(torch.load(f\"../vit_models/reconstruction/vit_{class_name}.pt\"))\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_class(class_name: str):\n",
    "    vit_model = get_vit_model(class_name)\n",
    "\n",
    "    train_tasad_and_vitcnn(class_name, vit_model, learning_rate=0.0001, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['bottle','cable','capsule','carpet','grid','hazelnut','leather','metal_nut','pill','screw','tile','toothbrush','transistor','wood','zipper']\n",
    "for class_name in classes:\n",
    "    train_class(class_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
